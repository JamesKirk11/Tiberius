This is a rough work flow for reducing and preparing ACAM & EFOSC light curves. What follows is focussed on reducing ACAM data but the process is very similar for EFOSC.

First things first, open the run log (if there is one) to get an idea what kind of files we have and roughly how many.

## 1) SORTING FITS FILES ##

In the directory containing all raw fits files, we need to find what each fits file corresponds to. 

First, look at the run log text file and find a frame that corresponds to a science image of the principal target (the frame that you choose should be a spectral frame, not a through-slit image, i.e. when you open it, you should see a streak of light covering most of the detector). Note the file name of the file you've chosen.

Open the science image in DS9 and record the windows used for the image and the position that the windows were defined in. For example, for an ACAM observation where window 2 is enabled (called 'WINSEC2' in ACAM fits headers) and is defined as '[180:1900,1100:3100]', for observations of 'WASP-39B', we would do:

$ python sort_ACAM_files.py -w1 [180:1900,1100:3100] -p1 2

Where -w1 corresponds to the window and -p1 corresponds to the position of that window (window 2 in this case). If you are working with > 1 window, open this as a multi extension fits file with DS9 by adding the -mecube option when calling DS9 from the command line. 

Running the above python script will save multiple lists of files names where the names give the type of images ('bias/flat/object'), whether the slit ('Xarcsec') and grism ('V400') were in place and put images that used a window different to that used for the science in a lists with 'wrong_window' in the name.



## 2) MAKING BIAS FRAMES AND FLAT FIELDS ##

With the list of bias files from step 1, do

$ python master_bias.py [name of list containing bias files] -v

This will median combine and save all bias frames into a single master_bias.fits file. The -v argument plots each frame to the screen which is necessary to make sure each individual bias frame is well behaved (no striping or strange electronics effects).

Now use this to make the flat field.

$ python master_flat.py [name of list containing flat files] -v -b master_bias.fits

This will ask you to choose a number for the box width of the running median. Experiment with this to see how well the sky/lamp lines are removed from the flat field. This is typically somewhere between 3 & 11 data points. Open up the resulting images in DS9 to check the output.

Do this for lamp and sky flats both with and without the slit.

At this stage, we can also create cosmic pixels masks (note that bad pixel masks are now created by master_flat.py). To create a cosmic pixel mask do:

$ python locate_cosmics.py [name of list containing flat files] 


## 3) EXTRACT SPECTRA ##

Make reduction directory for each new reduction.

Open extraction_input.txt and edit as appropriate. Before running reduction on all data it is a good idea to set the verbose parameter in the input file to -2 to make sure the background fits and aperture widths are performing correctly.

$ python spectral_extraction.py

Following this, the output will consist of a number of saved (pickled) numpy arrays (.pickle files). The output of these can be plotted via

$ python generate_ancillary_plots.py

Now also check the quality of the white light curve (saved in white_light.dat file). To use this you must make a text file (called 'system_params.dat') that contains the planet's period, a/Rs (+ error), inclination (+ error) and Rp/Rs (+ error). These parameters can be taken from TEPCAT (https://www.astro.keele.ac.uk/jkt/tepcat/). 

...........................................................
This section needs updating.....
Now run 

$ python white_light_fitting.py -h

where -h gives information about the additional parameters that this python file takes. This plots the white light curve and prints the RMS of the residuals which can be compared between reductions to obtain the optimal extraction parameters.

Note that some cases it can be preferable to use the fitting_utils functions to fit the white light curves if a simple time polynomial is not sufficient to model the systematics in the data.

Also at this stage, night movies can be made if there are weird features in the white light curve.
...........................................................


## 4) GO THROUGH REDUCTION NOTEBOOKS ##

This guides you through 

1) cosmic ray removal from the extracted spectra 
2) wavelength solution from the arc spectra
3) resampling of spectra to bring the 1D spectra into alignment
4) wavelength calibration of aligned spectra
5) wavelength binning - splitting the time series of 1D spectra into wavelength bins to make the spectroscopic light curves
6) white light preparation - make a new white light curve following alignment of the spectra and prepare the ancillary data (FWHM, airmass etc) for fitting


## 5) FIT THE DATA ##

See fitting_utils directory for this.





